---
title: "English Premier League Exploratory Analysis"
author: "Jai D. Bansal"
output: word_document
---


This report conducts exploratory analysis using English Premier League match data from the 2003/2004 season to the 2015/2016 season. The data can be obtained from: http://www.football-data.co.uk/englandm.php

This document contains result, plots, and interpretation. The underlying code is in 'premier_league_exploratory_analysis.Rmd'.

```{r prep_import_and_clean, include = F, echo = F}
  
  # Load packages.
  library(data.table)
  library(qdapRegex)
  library(ggplot2)
  library(reshape2)
  library(randomForest)
  library(caret)
  library(e1071)

  # Import data.
  # The working directory should be the 'premier-league-data-analysis' folder.
  premier_data = data.table(read.csv('premier_data.csv', 
                                     header = T, 
                                     stringsAsFactors = F))

  # Change 'Date' to date format.
  # This was done in 'data_aggregation_and_cleaning.R' but must be done again since 'Date' gets imported as a 'character' vector.
  premier_data$Date = as.Date(premier_data$Date, 
                              '%Y-%m-%d')
  
  # Make all text fields lowercase and remove extra whitespace.
  premier_data$HomeTeam = rm_white(tolower(premier_data$HomeTeam))
  premier_data$AwayTeam = rm_white(tolower(premier_data$AwayTeam))
  premier_data$Referee = rm_white(tolower(premier_data$Referee))

  # Remove features from 'premier_data' and put them into 'feature_data'.
  # 'feature_data' is used in the 'Match Outcome Prediction' section.
  # I do this to remove clutter and allow the data to be viewed more easily.
  feature_data = premier_data[, .(FTR, home_team_wins, away_team_wins, home_avg_goals, away_avg_goals, home_avg_sot, away_avg_sot, home_avg_corner, away_avg_corner, home_avg_foul, away_avg_foul, home_avg_yellow, away_avg_yellow, home_avg_red, away_avg_red)]
  premier_data = premier_data[, .(Date, HomeTeam, AwayTeam, FTHG, FTAG, FTR, Referee, HS, AS, HST, AST, HC, AC, HF, AF, HY, AY, HR, AR, season_num)]

```

Below is a sample of the data and some summary statistics. I've removed columns that aren't used in the analysis (half time goals and results, total shots, and some betting odds).   
These might be used in future iterations.


### Data Sample:

```{r view_data, echo = F}

  # View data sample.
  head(premier_data, 3)

```


The abbreviated columns stand for:
* FTHG: home team goals at end of match   
* FTAG: away team goals at end of match   
* FTR: match result ([h, a, d] denote [home team victory, away team victory, draw] respectively)   
* HST: home team shots on target   
* AST: away team shots on target   
* HC: home team corner kicks   
* AC: away team corner kicks   
* HF: home team fouls   
* AF: away team fouls   
* HY: home team yellow cards   
* AY: away team yellow cards   
* HR: home team red cards   
* AR: away team red cards   
* season_num: I added this in 'data_aggregation_and_cleaning.R' to indicate which season a match occurred in

### Summary Statistics:

* First Match Date: `r min(premier_data$Date)`
* Last Match Date: `r max(premier_data$Date)`
* Number of Seasons: `r length(unique(premier_data$season_num))`
* Number of Matches: `r nrow(premier_data)`
* Number of Teams: `r length(unique(premier_data$HomeTeam))`
* Number of Referees: `r length(unique(premier_data$Referee))`
* % of Matches Won by Home Team: `r round(100 * nrow(premier_data[FTR == 'h']) / nrow(premier_data), 2)`
* % of Matches Won by Away Team: `r round(100 * nrow(premier_data[FTR == 'a']) / nrow(premier_data), 2)`
* % of Matches Ending in a Draw: `r round(100 * nrow(premier_data[FTR == 'd']) / nrow(premier_data), 2)`

### Relegation:

At the end of each season, the bottom 3 teams in the standings are relegated to a lower division.
The English Premier League (EPL) is the top English league, so teams cannot be 'promoted' out of the league.
I will look at how many seasons the teams in our dataset have spent in the EPL.

```{r relegation_1, echo = T, include = F}
  
    # I need to do this section in 2 chunks to get the output correct.

    # Count seasons played by each team.
    premier_data[, 
                 seasons_played := length(unique(season_num)), 
                 by = 'HomeTeam']

```

```{r relegation_2, echo = F}

    # Create unique table with 1 row per team.
    seasons = premier_data[, .(HomeTeam, seasons_played)]
    seasons = unique(seasons)
    
    # Create table with number of teams and how many seasons they played.
    # I use 'data.frame' here instead of 'data.table' to get the output to look how I want it.
    seasons_result = data.frame(table(seasons$seasons_played))
    setnames(seasons_result, 
             names(seasons_result), 
             c('Seasons', 'Teams'))

    # Show 'seasons_result'.
    print(seasons_result)
    
```

Out of `r length(unique(premier_data$HomeTeam))` teams in the data, 6 (`r round(100 * 6/38, 1)`%) only spent 1 year in the EPL.
8 teams (`r round(100 * 8/38, 1)`%) spent 13 years, the longest time possible in this data set.
The average number of seasons spent in the EPL is `r round(mean(seasons$seasons_played), 1)`.
Note that large numbers of teams played 13 seasons and 1 season, with relatively low numbers of teams for the number of seasons in between.

This data implies that there are many teams that break into the EPL from a lower division...and are promptly relegated the following year.
It also implies that there is a group of dominant teams that are rarely relegated.
Looking at the clubs that played all 13 seasons in the EPL (`r seasons[seasons_played == 13]$HomeTeam`) reveals many well-known (and wealthy) teams.

**Further Exploration**:

* Look for differences between teams that were promoted to the EPL and stayed there as opposed to teams that were promoted and then relegated the next year.

### Best of the Best and Worst of the Best:

In this section, I plot the win percentages over time of 4 teams (I only use 4 teams so the plot is readable). Win percentage is defined as (# of wins / # of matches). I only use teams that are in the data set for every season. This is an important bias. Teams that are in the data every season are consistently above a certain quality as they do not get relegated. Simply put, they are the best teams. I will plot the top 2 teams (best of the best) and the worst 2 teams (worst of the best).

```{r best_worst, fig.width = 6, fig.height = 4.5, echo = F}
   
    # Create 'winner' column in 'premier_data'. This helps with counting below.
    premier_data$winner = ifelse(premier_data$FTR == 'h', premier_data$HomeTeam, 
                                 ifelse(premier_data$FTR == 'a', premier_data$AwayTeam, 'draw'))
    
    # Create 'team_season_list' of all teams in all games specified by season. This helps with counting below.
    home_team_seasons = premier_data[, .(HomeTeam, season_num)]
    away_team_seasons = premier_data[, .(AwayTeam, season_num)]
    setnames(home_team_seasons, 
             names(home_team_seasons), 
             c('team', 'season_num'))
    setnames(away_team_seasons, 
             names(away_team_seasons), 
             c('team', 'season_num'))
    team_season_list = rbind(home_team_seasons, away_team_seasons)
    rm(home_team_seasons, away_team_seasons)

    # Restrict 'seasons' from above to only teams that played 13 seasons.
    seasons = seasons[seasons_played == 13]
    
    # Add 'total_wins','total_games', and a wins and games column for each season to 'seasons'. They're blank for now.
    seasons$total_win_percent = rep(NA, 
                                    nrow(seasons))
    seasons$s1_win_percent = rep(NA, 
                                 nrow(seasons))
    seasons$s2_win_percent = rep(NA, 
                                 nrow(seasons))
    seasons$s3_win_percent = rep(NA, 
                                 nrow(seasons))
    seasons$s4_win_percent = rep(NA, 
                                 nrow(seasons))
    seasons$s5_win_percent = rep(NA, 
                                 nrow(seasons))
    seasons$s6_win_percent = rep(NA, 
                                 nrow(seasons))
    seasons$s7_win_percent = rep(NA, 
                                 nrow(seasons))
    seasons$s8_win_percent = rep(NA, 
                                 nrow(seasons))
    seasons$s9_win_percent = rep(NA, 
                                 nrow(seasons))
    seasons$s10_win_percent = rep(NA, 
                                  nrow(seasons))
    seasons$s11_win_percent = rep(NA, 
                                  nrow(seasons))
    seasons$s12_win_percent = rep(NA, 
                                  nrow(seasons))
    seasons$s13_win_percent = rep(NA, 
                                  nrow(seasons))
    
    # Fill in all empty 'season' values.
    # I use a loop here (and few other times throughout the analysis).
    # Vectorized operations are much faster in R, but the structure of the data makes them challenging to implement.
    # The data set is small enough that running loops seems to be manageable.
    for (i in 1:nrow(seasons))
      {
        
        # Fill in win values.
        seasons$total_win_percent[i] = 100 * nrow(premier_data[winner == seasons$HomeTeam[i]]) / nrow(team_season_list[team == seasons$HomeTeam[i]])
        seasons$s1_win_percent[i] = 100 * nrow(premier_data[winner == seasons$HomeTeam[i] & season_num == 1]) / nrow(team_season_list[team == seasons$HomeTeam[i] & season_num == 1])
        seasons$s2_win_percent[i] = 100 * nrow(premier_data[winner == seasons$HomeTeam[i] & season_num == 2]) / nrow(team_season_list[team == seasons$HomeTeam[i] & season_num == 2])
        seasons$s3_win_percent[i] = 100 * nrow(premier_data[winner == seasons$HomeTeam[i] & season_num == 3]) / nrow(team_season_list[team == seasons$HomeTeam[i] & season_num == 3])
        seasons$s4_win_percent[i] = 100 * nrow(premier_data[winner == seasons$HomeTeam[i] & season_num == 4]) / nrow(team_season_list[team == seasons$HomeTeam[i] & season_num == 4])
        seasons$s5_win_percent[i] = 100 * nrow(premier_data[winner == seasons$HomeTeam[i] & season_num == 5]) / nrow(team_season_list[team == seasons$HomeTeam[i] & season_num == 5])
        seasons$s6_win_percent[i] = 100 * nrow(premier_data[winner == seasons$HomeTeam[i] & season_num == 6]) / nrow(team_season_list[team == seasons$HomeTeam[i] & season_num == 6])
        seasons$s7_win_percent[i] = 100 * nrow(premier_data[winner == seasons$HomeTeam[i] & season_num == 7]) / nrow(team_season_list[team == seasons$HomeTeam[i] & season_num == 7])
        seasons$s8_win_percent[i] = 100 * nrow(premier_data[winner == seasons$HomeTeam[i] & season_num == 8]) / nrow(team_season_list[team == seasons$HomeTeam[i] & season_num == 8])
        seasons$s9_win_percent[i] = 100 * nrow(premier_data[winner == seasons$HomeTeam[i] & season_num == 9]) / nrow(team_season_list[team == seasons$HomeTeam[i] & season_num == 9])
        seasons$s10_win_percent[i] = 100 * nrow(premier_data[winner == seasons$HomeTeam[i] & season_num == 10]) / nrow(team_season_list[team == seasons$HomeTeam[i] & season_num == 10])
        seasons$s11_win_percent[i] = 100 * nrow(premier_data[winner == seasons$HomeTeam[i] & season_num == 11]) / nrow(team_season_list[team == seasons$HomeTeam[i] & season_num == 11])
        seasons$s12_win_percent[i] = 100 * nrow(premier_data[winner == seasons$HomeTeam[i] & season_num == 12]) / nrow(team_season_list[team == seasons$HomeTeam[i] & season_num == 12])
        seasons$s13_win_percent[i] = 100 * nrow(premier_data[winner == seasons$HomeTeam[i] & season_num == 13]) / nrow(team_season_list[team == seasons$HomeTeam[i] & season_num == 13])
      
      }
    rm(i)
  
    # Order 'seasons' by 'total_win_percent'.
    seasons = seasons[order(total_win_percent, 
                            decreasing = T)]
    
    # Limit 'seasons' to top and bottom 2 teams.
    # Any more is hard to read on the plot.
    seasons = seasons[c(1:2, ((nrow(seasons) - 1):nrow(seasons))),]
    
    # Remove 'seasons_played' and 'total_win_percent' from 'seasons'. It's not needed.
    seasons$seasons_played = NULL
    seasons$total_win_percent = NULL
    
    # Rename 'seasons' columns for ease of plotting.
    setnames(seasons, 
             names(seasons),
             c('Team', '03-04', '04-05', '05-06', '06-07', '07-08', '08-09', '09-10', '10-11', '11-12', '12-13', '13-14', '14-15', '15-16'))
    
    # Rename 'seasons$Team' with proper team names.
    seasons$Team = c('Man. United', 'Chelsea', 'Everton', 'Aston Villa')
    
    # Reshape data for plotting.
    seasons_reshape = melt(seasons, 
                           id = 'Team')
    
    # Create plot.
    ggplot(data = seasons_reshape, 
           aes(x = variable, 
               y = value, 
               group = Team,
               color = Team)) +
      geom_line() +
      geom_point() +
      ylim(c(0, 100)) +
      ggtitle('Win Percentage of Selected Teams') +
      xlab('Season') +
      ylab('Win Percentage') +
      theme(axis.text.x = element_text(color = 'black', 
                                   size = 11, 
                                   angle = 45), 
      axis.text.y = element_text(color = 'black', 
                                   size = 13), 
      axis.title.x = element_text(size = 13),
      axis.title.y = element_text(size = 13,
                                  vjust = 1),
      axis.ticks = element_blank(),
      plot.title = element_text(face = 'bold', 
                                size = 13), 
      legend.title = element_text(size = 12),
      legend.text = element_text(size = 12))
     
```

All 4 of these teams are part of the dominant 8 that are never relegated in this data set. I find it surprising that Everton and Aston Villa (especially Aston Villa) are consistently below a win percentage of 50%. It seems that these clubs haven't done well recently, but haven't done poorly enough to be relegated. Finally, it's interesting that all 4 teams on the plot do worse, in some cases much worse, in the 2015-2016 season than the 2014-2015 season.

**Further Exploration**:

* Conduct this analysis with more teams.

### Clustering By Playing Style:

In this section, I will K-means to cluster all `r length(unique(premier_data$HomeTeam))` teams in the data by average fouls per game and average shots on net percentage per game. The latter quantity is computed by dividing the shots on net by total shots. I only cluster by two dimensions to allow easy visualization. Since different teams have spent different amounts of time in the EPL, it's important to use average quantities (and not totals).

```{r clustering, echo = F}
   
    # Clean up previous section artifacts.
  rm(seasons, team_season_list, seasons_reshape)
  
  # Create data table for clustering analysis with 1 row per team.
  cluster_data = data.table(team = unique(premier_data$HomeTeam), 
                            home_games = rep(NA, length(unique(premier_data$HomeTeam))), 
                            away_games = rep(NA, length(unique(premier_data$HomeTeam))),
                            home_fouls = rep(NA, length(unique(premier_data$HomeTeam))),
                            away_fouls = rep(NA, length(unique(premier_data$HomeTeam))),
                            home_shots_on_target = rep(NA, length(unique(premier_data$HomeTeam))),
                            away_shots_on_target = rep(NA, length(unique(premier_data$HomeTeam))),
                            home_shots = rep(NA, length(unique(premier_data$HomeTeam))),
                            away_shots = rep(NA, length(unique(premier_data$HomeTeam))))

  # Fill in 'cluster_data'.
  for (i in 1:nrow(cluster_data))
    {
    
      cluster_data$home_games[i] = nrow(premier_data[HomeTeam == cluster_data$team[i]])
      cluster_data$away_games[i] = nrow(premier_data[AwayTeam == cluster_data$team[i]])
      cluster_data$home_fouls[i] = sum(premier_data[HomeTeam == cluster_data$team[i]]$HF) 
      cluster_data$away_fouls[i] = sum(premier_data[AwayTeam == cluster_data$team[i]]$AF)
      cluster_data$home_shots_on_target[i] = sum(premier_data[HomeTeam == cluster_data$team[i]]$HST)
      cluster_data$away_shots_on_target[i] = sum(premier_data[AwayTeam == cluster_data$team[i]]$AST)
      cluster_data$home_shots[i] = sum(premier_data[HomeTeam == cluster_data$team[i]]$HS)
      cluster_data$away_shots[i] = sum(premier_data[AwayTeam == cluster_data$team[i]]$AS)
  
  }
  rm(i)
  
  # Compute total games, fouls, shots on target, and shots (home quantity + away quantity).
  cluster_data$games = cluster_data$home_games + cluster_data$away_games
  cluster_data$fouls = cluster_data$home_fouls + cluster_data$away_fouls
  cluster_data$shots_on_target = cluster_data$home_shots_on_target + cluster_data$away_shots_on_target
  cluster_data$shots = cluster_data$home_shots + cluster_data$away_shots
  
  # Compute average fouls per game and average shot percentage per game for each team.
  cluster_data$avg_fouls = cluster_data$fouls / cluster_data$games
  cluster_data$avg_shots_on_target_percent = 100 * cluster_data$shots_on_target / cluster_data$shots
  
  # Scale 'avg_fouls' and 'avg_shots_on_target_percent'. This should be done prior to clustering.
  # I do this separately so I can later access the mean and standard deviation of scaling.
  avg_fouls_scaled = scale(cluster_data$avg_fouls)
  avg_shots_on_target_percent_scaled = scale(cluster_data$avg_shots_on_target_percent)
  
  # Add 'avg_fouls_scaled' and 'avg_shots_on_target_percent_scaled' to 'cluster_data'.
  cluster_data$avg_fouls_scaled = avg_fouls_scaled
  cluster_data$avg_shots_on_target_percent_scaled = avg_shots_on_target_percent_scaled
  
  # Conduct K-means clustering with 4 clusters.
  cluster_kmeans = kmeans(cluster_data[, .(avg_fouls_scaled, avg_shots_on_target_percent_scaled)], 
                          centers = 4)
  
  # Convert cluster centers back into unscaled values.
  cluster_centers = data.table(cluster_kmeans$centers)
  cluster_centers$avg_fouls_scaled = (cluster_centers$avg_fouls_scaled * attr(avg_fouls_scaled, 'scaled:scale')) + 
                                      attr(avg_fouls_scaled, 'scaled:center')
  cluster_centers$avg_shots_on_target_percent_scaled = (cluster_centers$avg_shots_on_target_percent_scaled * attr(avg_shots_on_target_percent_scaled, 'scaled:scale')) + attr(avg_shots_on_target_percent_scaled, 'scaled:center')
  
  # Add clusters to 'cluster_data'.
  cluster_data$clusters = cluster_kmeans$cluster
  
  # View cluster means.
  cluster_centers$avg_fouls_scaled = round(cluster_centers$avg_fouls_scaled, 1)
  cluster_centers$avg_shots_on_target_percent_scaled = round(cluster_centers$avg_shots_on_target_percent_scaled, 1)
  setnames(cluster_centers, names(cluster_centers), c('Average Fouls', 'Avg. Shots on Net %'))
  cluster_centers
  
  # Plot clusters.
  ggplot(data = cluster_data[, .(avg_fouls, avg_shots_on_target_percent, clusters)], 
         aes(x = avg_fouls, 
             y = avg_shots_on_target_percent, 
             group = as.character(clusters),
             color = as.character(clusters))) +
    geom_point(size = 2, 
               aes(shape = as.character(clusters))) +
    scale_color_manual(values = c('red', 'blue', 'yellow', 'black')) +
    theme(axis.text.x = element_text(color = 'black', 
                                     size = 13), 
          axis.text.y = element_text(color = 'black', 
                                     size = 13), 
          axis.title.x = element_text(face = 'bold', 
                                    size = 13),
          axis.title.y = element_text(face = 'bold',
                                      size = 13, 
                                      vjust = 1),
          axis.ticks = element_blank(),
          plot.title = element_text(face = 'bold', 
                                    size = 13)) +
    guides(colour = F, 
           shape = F) +
    ggtitle('Clustered EPL Teams') +
    xlab('Average Fouls Per Game') +
    ylab('Avg. Shots on Net % Per Game')
 
```

Oddly enough, RMarkdown output has different colors/shapes in different positions everytime This needs to be filled in properly in the final version. The  <> cluster represents teams with many fouls and relatively high shot accuracy. The <> cluster commits less fouls than the blue cluster and has a slightly lower accuracy. The <> cluster is characterized by a lower shot accuracy. The <> cluster admittedly looks like a miscellaneous cluster, but is generally characterized by lower shot accuracy and fouls.

**Further Exploration**:

* Add more dimensions to the clustering.

### Match Outcome Prediction:

In this section, I predict the outcome of matches (home win, away win, draw) using a random forest.   
I use features (wins, average goals per match, average on-target shots per match, average corner kicks per match, average fouls per match, average yellow cards per match, average red cards per match) from the **same season** only.   
Each feature is computed for the home and away teams of the match.

For example, suppose team A is playing team B in season 2. I would compute all features for both teams using only previous matches in season 2.   
This method means that I cannot obtain predictions for a team's 1st match of the season.  
For a team's 2nd match of the season, I will obtain predictions using only data from that team's 1st match.
For a team's 10th match, I obtain predictions using data from the 1st 9 matches.   
So, each team's features are being updated every match.

The 'randomforest' package provides a graphic showing which features are the most important according to 2 different metrics.

```{r match_outcome_prediction_initial, echo = F}
  
  # Remove unneeded objects:
  rm(avg_fouls_scaled, avg_shots_on_target_percent_scaled, cluster_centers, cluster_data, seasons_result, cluster_kmeans)

  # This section uses 'feature_data'.
  # Recall that, for each match, features from previous matches in the same season for the relevant teams are used for prediction.
  # Thus, for a team's first match of the season, no prediction is possible.
  # I remove these rows from 'feature_data'.
  feature_data = feature_data[is.na(home_avg_goals) == F & is.na(away_avg_goals) == F]

  # For classification, 'feature_data$FTR' must be of type 'factor'.
  feature_data$FTR = as.factor(feature_data$FTR)

  # Create training and test sets from 'feature_data'.
  # I use ~70% of the data for training.
  # The remaining ~25% of the data is used as a test set.
  
    # Randomly choose rows to be in training set.
    training_rows = sample(1:nrow(feature_data), 
                           round(0.70 * nrow(feature_data)), 
                           replace = F)

    # Create training and test sets.
    feature_data_train = feature_data[training_rows]
    feature_data_test = feature_data[-training_rows]

  # Specify model.
  match_model = FTR ~.

  # Set seed for reproducibility.
  set.seed(25)

  # Create random forest.
  match_rf = randomForest(match_model, 
                          data = feature_data_train,
                          ntree = 250, 
                          importance = T)

  # Add OOB (out-of-bag) training set predictions to 'feature_data_train'.
  # The OOB score can be substituted for a cross validation score when using random forest.
  feature_data_train$oob_pred = match_rf$predicted

  # Generate predictions for training and test sets.
  feature_data_train$train_pred = data.table(predict(match_rf, 
                                               newdata = feature_data_train, 
                                               type = 'response'))
  feature_data_test$test_pred = data.table(predict(match_rf, 
                                               newdata = feature_data_test, 
                                               type = 'response'))

  # Show plot of variable importances.
  varImpPlot(match_rf)

```

Creating a random forest out of the box, I obtain:   
- training set error of `r 100 * round(nrow(feature_data_train[FTR != train_pred]) / nrow(feature_data_train), 4)`%   
- OOB (out-of-bag) sample error `r 100 * round(nrow(feature_data_train[FTR != oob_pred]) / nrow(feature_data_train), 4)`% (I use this as a cross-validation error)   
- test set error of `r 100 * round(nrow(feature_data_test[FTR != test_pred]) / nrow(feature_data_test), 4)`%

The baseline model I compare against is predicting a home team win every time (this yields an error of `r 100 * round(nrow(feature_data_test[FTR != 'h']) / nrow(feature_data_test), 4)`% on the test set)

So, the random forest model is slightly better than the always predicting the home team wins. Below, I try to improve on the inital random forest model using feature selection and parameter tuning. The training set error (0%) indicates I have an overfitting problem.

```{r feature_selection, echo = F}

  # This section is commented out because it takes too long to run every time.
  # I include findings from when this code was run, it's just not run every time.
  # These results also vary with the random seed that is set.

  # Set seed for reproducibility.
  #set.seed(25)

  # Define the control function for random forest functions.
  # This will be used to specify some of the parameters of the feature selection.
  #control = rfeControl(functions = rfFuncs,             # random forest functions
  #                   method = 'cv',                     # cross validation
  #                   number = 5, ,                      # number of folds
  #                   allowParallel = T, 
  #                   verbose = T)

  # Conduct backwards recursive feature selection.
  #results = rfe(x = feature_data_train[, .(home_team_wins, away_team_wins, home_avg_goals, away_avg_goals, home_avg_sot, away_avg_sot, home_avg_corner, 
  #                                       away_avg_corner, home_avg_foul, away_avg_foul, home_avg_yellow, away_avg_yellow, home_avg_red, away_avg_red)], 
  #              y = feature_data_train$FTR, 
  #              sizes = c(1:14), 
  #              rfeControl = control)

  # View plot of results.
  #plot(results)

  # See the best predictors
  #predictors(results)

```

Using backwards recursive feature selection, I see that using 12 features results in a slightly more accurate model
than using the entire feature set. I will use this modified model for parameter tuning.

Note that I ran the feature selection code and noted the results, but it is now commented out. It makes the generation of this document take way too long.

The 2 features that are removed are 'away_avg_foul' and 'home_avg_yellow'.

```{r parameter_tuning, echo = F}

  # This section is commented out because it takes too long to run every time.
  # I include findings from when this code was run, it's just not run every time.

  # Remove unneeded objects.
  rm(training_rows)

  # Specify model found from feature selection.
  best_model = FTR ~ home_team_wins + away_team_wins + home_avg_goals + away_avg_goals + home_avg_sot + away_avg_sot + home_avg_corner + away_avg_corner + home_avg_foul + away_avg_yellow + away_avg_red + home_avg_red

  # Set seed for reproducibility.
  set.seed(25)

  # Create 'parameters' data table containing all of the parameters combinations I want to try.
  parameters = expand.grid(ntree = c(250, 500, 750), 
                           mtry = c(2, 3, 4, 5), 
                           nodesize = c(1, 5, 10))

  # Create columns in 'parameters' for training, OOB, and test set error.
  parameters$train_error = rep(NA, 
                               nrow(parameters))
  parameters$oob_error = rep(NA, 
                             nrow(parameters))
  parameters$test_error = rep(NA, 
                              nrow(parameters))

  # Loop through the rows of 'parameters' and fit a random forest for each combination of parameters.
  for (i in 1:nrow(parameters))
    {
    
      # Keep track of loop progress.
      print(i)
    
      # Create random forest model.
      rf_parameter_test = randomForest(best_model, 
                                       data = feature_data_train, 
                                       ntree = parameters$ntree[i],
                                       mtry = parameters$mtry[i], 
                                       nodesize = parameters$nodesize[i])
      
      # Save predictions so I can compute error rates.
      
        # Add OOB training set predictions to 'feature_data_train'.
        feature_data_train$oob_pred = rf_parameter_test$predicted
  
        # Generate predictions for training and test sets.
        feature_data_train$train_pred = data.table(predict(rf_parameter_test, 
                                                           newdata = feature_data_train, 
                                                           type = 'response'))
        feature_data_test$test_pred = data.table(predict(rf_parameter_test, 
                                                         newdata = feature_data_test, 
                                                         type = 'response'))
      
      # Compute training, OOB, and test set errors and store values in 'parameters'.
      
        # Training error.
        parameters$train_error[i] = nrow(feature_data_train[FTR != train_pred]) / nrow(feature_data_train)
      
        # OOB error.
        parameters$oob_error[i] = nrow(feature_data_train[FTR != oob_pred]) / nrow(feature_data_train)
      
        # Test error.
        parameters$test_error[i] = nrow(feature_data_test[FTR != test_pred]) / nrow(feature_data_test)  
    
    }

```

I tune 3 parameters in the random forest: the # of trees, the # of variables considered at each split, and the minimum node size of terminal nodes.   
Parameter tuning shows that the best values for [ntree, mtry, nodesize] are [, , ,] respectively.

Note that I ran the parameter tuning code and noted the results, but it is now commented out. It makes the generation of this document take way too long.





More ideas:
- referee analysis
- look at datascience blog posts to see what else
   